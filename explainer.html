<title>
notes
</title>
<!-- <link rel="stylesheet" href="https://acdlite.github.io/jquery.sidenotes/css/main.css"> -->
<!-- https://tscanlin.github.io/tocbot/ -->
<!-- <link rel="stylesheet" href="https://tscanlin.github.io/tocbot/static/css/styles.css" class="next-head"> -->
<p><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css"></p>
<p><link rel="stylesheet" href="lib/styles.css" class=next-head></p>
<p><link rel="stylesheet" href="styles/toolkit-styles.css" class="next-head"></p>
<div class="mw7 center dark-gray lh-copy all-content">
<p><nav class="toc toc-right js-toc relative z-1 transition--300 absolute pa4 is-position-fixed"> </nav></p>
<!-- <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script> -->
<!-- <script src="lib/comments/inlineDisqussions.js"></script> -->
<!-- <link rel="stylesheet" type="text/css" href="inlineDisqussions.css" /> -->
<div class="content js-toc-content pa4">
<!-- <script -->
<!--   src="https://code.jquery.com/jquery-3.4.1.min.js" -->
<!--     integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" -->
<!--      crossorigin="anonymous"></script> -->
<!-- <script src="lib/annotator-full.1.2.10/annotator-full.min.js"></script> -->
<!-- <link rel="stylesheet" href="lib/annotator-full.1.2.10/annotator.min.css"> -->
<h1 id="toward-a-rich-explanatory-medium-for-deep-learning-models">Toward a rich explanatory medium for deep learning models</h1>
<h2 id="the-idea">The idea</h2>
<p>Literate deep learning</p>
<p>no results for “literate deep learning” “literate machine learning”</p>
<p>Toward a rich explanatory medium for deep learning models</p>
<p>but hear me out—executable documentation explaining visually how machine learning models work, with references to the real model running in the browser.</p>
<p>What does a rich explanatory medium for deep learning models need?</p>
<p>This has input-output examples, math notation, prose, and pictures — for <sub>people</sub> — and linking that to the runnable code. It needs references/deeplinks to the code, and the ability to run examples in the browser, visually.</p>
<p>the point is that the domain has its own domain-specific language of biases, weights, layers, inputs, outputs, etc. that can be modeled in a DSL?</p>
<p>What does it NOT need? The ability to develop new models.</p>
<p>Like, can we make something as good as the mathigon environment but for machine learning models (or hi-assurance models) (running in the browser) https://mathigon.org/course/fractals/introduction</p>
<p>IDEAL DEMO: TODO</p>
<h2 id="motivation-and-applications">Motivation and applications</h2>
<p>I’m actually thinking something like these NIST high-assurance specs, or other documents that vendors provide. People HAVE TO WRITE IT https://csrc.nist.gov/publications/detail/sp/800-90a/archive/2012-01-23</p>
<p>how do people do algorithmic accountability stuff, like, now, how does the government audit</p>
<p>this could be good for hi-assurance executable specs for legislation, etc?</p>
<p>strong positive signal from angela — seems super necessary, etc.</p>
<h2 id="related-work">Related work</h2>
<p>This is not for figuring out why your model isn’t doing the thing it was supposed to do. This is not for debugging or making models or transparency, this is for explaining and referring to an existing model.</p>
<p>This is not a computational notebook (e.g. colab or jupyter), which is for really running and building the thing.</p>
<ul>
<li>distill colab nb https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/activation-atlas/activation-atlas-simple.ipynb</li>
<li>See in this notebook, they still put in pictures and notation. Also Q&amp;A format? http://d2l.ai/chapter_multilayer-perceptrons/mlp-scratch.html#the-loss-function</li>
<li>https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_convolutional-neural-networks/pooling.ipynb#scrollTo=Ql_gtyIxNkJO</li>
</ul>
<p>This is not Dan Amelang's thing, which is great but is for really modeling industrial-strength NNs.</p>
<ul>
<li>of course, dan amelang’s work is the closest https://app.reduct.video/e/the-dynamic-media-dream-e4ed367417-4d5acec7aeed995cf021/</li>
</ul>
<p>This is not a visual environment for making ML models, like Runway or Lobe.</p>
<ul>
<li>https://runwayml.com/</li>
<li>sony NN console https://dl.sony.com/console/#/project https://support.dl.sony.com/docs/tutorial-training-using-a-sample-project/</li>
</ul>
<p>This is not a neural network playground.</p>
<ul>
<li>Obviously super related https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.05915&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false</li>
</ul>
<p>This is not model cards or datasheets for datasets!</p>
<ul>
<li>Model cards (fat* ’19) https://arxiv.org/pdf/1810.03993.pdf</li>
<li>Datasheets for datasets (workshop on FATML, ’18) https://www.microsoft.com/en-us/research/uploads/prod/2019/01/1803.09010.pdf</li>
</ul>
<p>This is not an architecture visualization library</p>
<ul>
<li>People still can’t draw diagrams https://datascience.stackexchange.com/questions/14899/how-to-draw-deep-learning-network-architecture-diagrams https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network</li>
</ul>
<p>This is not a neural network textbook or journal article. obviously distill does it well (like the conv net windows)—but those aren’t explainers to technical people? more like research papers?</p>
<ul>
<li>idyll has some nice work on explainers: https://idyll-lang.org/gallery/the-beginner-s-guide-to-dimensionality-reduction</li>
</ul>
<h2 id="research-questions-and-challenges">Research questions and challenges</h2>
<p>Questions</p>
<ul>
<li>TODO</li>
</ul>
<p>Challenges</p>
<ul>
<li>TODO</li>
</ul>
<h2 id="technical-next-steps">Technical next steps</h2>
<p>can we explain tf.js demos? https://www.tensorflow.org/js/demos</p>
<p>https://github.com/tensorflow/tfjs-models/blob/master/posenet/src/posenet_model.ts</p>
<p>https://github.com/tensorflow/tfjs-models/blob/master/knn-classifier/demo/index.js</p>
<p>Are there already specs for high-assurance algos https://ainowinstitute.org/aap-toolkit.pdf</p>
<p>does tf.js have a tensorboard equivalent?</p>
<p>I mean, at this point, you need to really be able to understand and explain the models yourself?</p>
<p>Who has done this by hand, but really well?</p>
</div>
</div>
<!-- <script> -->
<!-- disqus_shortname = 'fluid_media'; -->
<!-- jQuery(document).ready(function() { -->
<!--    jQuery("p").inlineDisqussions(); -->
<!-- }); -->
<!-- </script> -->
<!-- <div id="commento"></div> -->
<!-- <script defer src="https://cdn.commento.io/js/commento.js"></script> -->
<script
  src="https://code.jquery.com/jquery-3.4.1.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
      crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js"></script>
<script src="lib/jquery.sidenotes.js"></script>
<script>
 $(() => {
     console.log("ready");

     tocbot.init({
     // Where to render the table of contents.
     tocSelector: '.js-toc',
     // Where to grab the headings to build the table of contents.
     contentSelector: '.js-toc-content',
     // Which headings to grab inside of the contentSelector element.
     headingSelector: 'h1, h2, h3',
     // For headings inside relative or absolute positioned containers within content.
     hasInnerContainers: true,
     });

     $(".footnotes").appendTo(".all-content");

     /*      $('.all-content').sidenotes();*/
 });
</script>
